---
---

----------------------------------------------------------------------------------------------------------------------------
--- 2025
----------------------------------------------------------------------------------------------------------------------------

@InProceedings{10.1007/978-3-032-05185-1_63,
author="Maccarone, Francesca
and Longari, Giorgio
and Arrigoni, Filippo
and Peruzzo, Denis
and Melzi, Simone",
editor="Gee, James C.
and Alexander, Daniel C.
and Hong, Jaesung
and Iglesias, Juan Eugenio
and Sudre, Carole H.
and Venkataraman, Archana
and Golland, Polina
and Kim, Jong Hyo
and Park, Jinah",
title="Unraveling Brainstem Deformations in Joubert Syndrome: A Statistical Shape Analysis of MRI-Derived Structures",
booktitle="Medical Image Computing and Computer Assisted Intervention -- MICCAI 2025",
year="2026",
publisher="Springer Nature Switzerland",
address="Cham",
pages="659--669",
abstract="Statistical shape analysis (SSA) is a powerful tool for studying anatomical structures and their geometric variations in medical imaging. In this work, we analyze real MRI-derived data to explore correlations between geometric deformations and Joubert syndrome (JS). Building on prior SSA research, we tailor the preprocessing pipeline to an in-house dataset and perform a detailed shape variability analysis using principal component analysis (PCA). A random forest classifier is then applied, achieving high classification accuracy. To ensure robustness, we test multiple train-test splits and evaluate their impact. In addition, we support clinical interpretation by providing visualizations that combine 3D and 2D information, resembling typical diagnostic paradigms on MRI planes. Our work offers some methodological insights into shape-based analysis and aims to serve as a practical tool for the medical community. Code and data are openly available at: https://github.com/Franca-exe/SSA-brainstem.",
isbn="978-3-032-05185-1"
}


@inproceedings{
    baieri2025implicitarap,
    title={Implicit-{ARAP}: Efficient Handle-Guided Neural Field Deformation via Local Patch Meshing},
    author={Baieri, Daniele and Maggioli, Filippo and Rodolà, Emanuele and Melzi, Simone and Lähner, Zorah},
    booktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},
    year={2025},
    url={https://openreview.net/forum?id=zp7W2QmxHS}
}

@article{vigano2025nam,
    title = {NAM: Neural Adjoint Maps for refining shape correspondences},
    journal = {Transactions On Graphics},
    volume = {122},
    pages = {103985},
    year = {2025},
    selected = {true},
    abbr = {SIGGRAPH},
    issn = {0097-8493},
    doi = {https://doi.org/10.1145/3730943},
    url = {https://www.lix.polytechnique.fr/~maks/papers/NAM_SIGGRAPH2025.pdf},
    author = {Viganò, Giulio and Ovsjanikov, Maks and Melzi, Simone},
    keywords = {Shape correspondence, Functional maps, Point clouds, Machine
                learning},
    preview = {graphical_abstract_1494.jpg},
}

@misc{blend25,
    abbr = {Preprint},
    title = {Blending Concepts with Text-to-Image Diffusion Models},
    author = {Lorenzo Olearo and Giorgio Longari and Alessandro Raganato and
              Rafael Peñaloza and Simone Melzi},
    year = {2025},
    eprint = {2506.23630},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2506.23630},
    abstract = { Diffusion models have dramatically advanced text-to-image
                generation in recent years, translating abstract concepts into
                high-fidelity images with remarkable ease. In this work, we
                examine whether they can also blend distinct concepts, ranging
                from concrete objects to intangible ideas, into coherent new
                visual entities under a zero-shot framework. Specifically,
                concept blending merges the key attributes of multiple concepts
                (expressed as textual prompts) into a single, novel image that
                captures the essence of each concept. We investigate four
                blending methods, each exploiting different aspects of the
                diffusion pipeline (e.g., prompt scheduling, embedding
                interpolation, or layer-wise conditioning). Through systematic
                experimentation across diverse concept categories, such as
                merging concrete concepts, synthesizing compound words,
                transferring artistic styles, and blending architectural
                landmarks, we show that modern diffusion models indeed exhibit
                creative blending capabilities without further training or
                fine-tuning. Our extensive user study, involving 100 participants
                , reveals that no single approach dominates in all scenarios:
                each blending technique excels under certain conditions, with
                factors like prompt ordering, conceptual distance, and random
                seed affecting the outcome. These findings highlight the
                remarkable compositional potential of diffusion models while
                exposing their sensitivity to seemingly minor input variations. },
    pdf = {https://arxiv.org/pdf/2506.23630},
    html = {https://arxiv.org/abs/2506.23630},
    preview = {preview-blending-concepts.png},
}

@inproceedings{Hadgi_2025_CVPR,
    author = {Hadgi, Souhail and Moschella, Luca and Santilli, Andrea and Gomez,
              Diego and Huang, Qixing and Rodol\`a, Emanuele and Melzi, Simone
              and Ovsjanikov, Maks},
    title = {Escaping Plato's Cave: Towards the Alignment of 3D and Text Latent
             Spaces},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and
                 Pattern Recognition (CVPR)},
    month = {June},
    year = {2025},
    pages = {19825-19835},
    doi = {10.48550/arXiv.2503.05283},
    url = {
           https://openaccess.thecvf.com/content/CVPR2025/papers/Hadgi_Escaping_Platos_Cave_Towards_the_Alignment_of_3D_and_Text_CVPR_2025_paper.pdf
           },
}

----------------------------------------------------------------------------------------------------------------------------
--- 2024
----------------------------------------------------------------------------------------------------------------------------

@inproceedings{maggioli2024rematching,
    author={Maggioli, Filippo and Baieri, Daniele and Rodolà, Emanuele and Melzi, Simone},
    editor={Leonardis, Ale{\v{s}} and Ricci, Elisa and Roth, Stefan and Russakovsky, Olga and Sattler, Torsten and Varol, G{\"u}l},
    title={ReMatching: Low-Resolution Representations for Scalable Shape Correspondence},
    booktitle={Computer Vision -- ECCV 2024},
    year={2025},
    publisher={Springer Nature Switzerland},
    address={Cham},
    pages={183--200},
    abstract={We introduce ReMatching, a novel shape correspondence solution based on the functional maps framework. Our method, by exploiting a new and appropriate re-meshing paradigm, can target shape-matching tasks even on meshes counting millions of vertices, where the original functional maps does not apply or requires a massive computational cost. The core of our procedure is a time-efficient remeshing algorithm which constructs a low-resolution geometry while acting conservatively on the original topology and metric. These properties allow translating the functional maps optimization problem on the resulting low-resolution representation, thus enabling efficient computation of correspondences with functional map approaches. Finally, we propose an efficient technique for extending the estimated correspondence to the original meshes. We show that our method is more efficient and effective through quantitative and qualitative comparisons, outperforming state-of-the-art pipelines in quality and computational cost.},
    isbn={978-3-031-72913-3}
}




@inproceedings{maccarone2024sfora,
    booktitle = {Smart Tools and Applications in Graphics - Eurographics Italian
                 Chapter Conference},
    editor = {Caputo, Ariel and Garro, Valeria and Giachetti, Andrea and
              Castellani, Umberto and Dulecha, Tinsae Gebrechristos},
    title = {{S4A: Scalable Spectral Statistical Shape Analysis}},
    author = {Maccarone, Francesca and Longari, Giorgio and Viganò, Giulio and
              Peruzzo, Denis and Maggioli, Filippo and Melzi, Simone},
    year = {2024},
    publisher = {The Eurographics Association},
    ISSN = {2617-4855},
    ISBN = {978-3-03868-265-3},
    DOI = {10.2312/stag.20241343},
}

@article{vigano2024bule,
    title = {Bijective upsampling and learned embedding for point clouds
             correspondences},
    journal = {Computers and Graphics},
    volume = {122},
    pages = {103985},
    year = {2024},
    issn = {0097-8493},
    doi = {https://doi.org/10.1016/j.cag.2024.103985},
    url = {https://www.sciencedirect.com/science/article/pii/S0097849324001201},
    author = {Viganò, Giulio and Melzi, Simone},
    keywords = {Shape correspondence, Functional maps, Point clouds, Machine
                learning},
}


@article{olearo2024blend,
    title = {How to Blend Concepts in Diffusion Models},
    author = {Lorenzo Olearo and Giorgio Longari and Simone Melzi and Alessandro
              Raganato and Rafael Peñaloza},
    journal = {arXiv preprint arXiv:2407.14280},
    abbr = {KGM @ ECCV},
    year = {2024},
    abstract = { For the last decade, there has been a push to use
                multi-dimensional (latent) spaces to represent concepts; and yet
                how to manipulate these concepts or reason with them remains
                largely unclear. Some recent methods exploit multiple latent
                representations and their connection, making this research
                question even more entangled. Our goal is to understand how
                operations in the latent space affect the underlying concepts. To
                that end, we explore the task of concept blending through
                diffusion models. Diffusion models are based on a connection
                between a latent representation of textual prompts and a latent
                space that enables image reconstruction and generation. This task
                allows us to try different text-based combination strategies, and
                evaluate easily through a visual analysis. Our conclusion is that
                concept blending through space manipulation is possible, although
                the best strategy depends on the context of the blend. },
    pdf = {https://arxiv.org/pdf/2407.14280},
    html = {https://arxiv.org/pdf/2407.14280},
    preview = {preview-how-to-blend-concepts.png},
}

@inproceedings{10.2312:stag.20241345,
    booktitle = {Smart Tools and Applications in Graphics - Eurographics Italian
                 Chapter Conference},
    editor = {Caputo, Ariel and Garro, Valeria and Giachetti, Andrea and
              Castellani, Umberto and Dulecha, Tinsae Gebrechristos},
    title = {{Localized Gaussians as Self-Attention Weights for Point Clouds
             Correspondence}},
    author = {Riva, Alessandro and Raganato, Alessandro and Melzi, Simone},
    year = {2024},
    publisher = {The Eurographics Association},
    abbr = {STAG},
    ISSN = {2617-4855},
    ISBN = {978-3-03868-265-3},
    DOI = {10.2312/stag.20241345},
    preview = {preview-riva-stag2024.png},
}
